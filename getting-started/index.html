
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://echosprint.github.io/TabularTransformer/getting-started/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../hyperparameters/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.35">
    
    
      
        <title>Getting started - TabularTransformer</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.35f28582.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
      <link rel="stylesheet" href="../css/table.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="grey">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#supervised-training-using-tabular-transformer" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="TabularTransformer" class="md-header__button md-logo" aria-label="TabularTransformer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            TabularTransformer
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Getting started
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/echosprint/TabularTransformer" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    echosprint/TabularTransformer
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="TabularTransformer" class="md-nav__button md-logo" aria-label="TabularTransformer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    TabularTransformer
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/echosprint/TabularTransformer" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    echosprint/TabularTransformer
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Getting started
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Getting started
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Preparation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-training" class="md-nav__link">
    <span class="md-ellipsis">
      Model Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Making Predictions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../hyperparameters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HyperParameters
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Embedding
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Preparation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-training" class="md-nav__link">
    <span class="md-ellipsis">
      Model Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Making Predictions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="supervised-training-using-tabular-transformer">Supervised training using <a href="https://github.com/echosprint/TabularTransformer">tabular-transformer</a><a class="headerlink" href="#supervised-training-using-tabular-transformer" title="Permanent link">&para;</a></h1>
<p>This notebook demonstrates how to use the TabularTransformer to efficiently handle a tabular data prediction task. We will walk through data preparation, model training, and prediction using a sample dataset.</p>
<p>TabularTransformer is an end-to-end training framework that processes raw data directly, eliminating the need for handcrafted features and complex preprocessing steps. It provides a competitive alternative to tree-based models for handling tabular data.</p>
<p><a target="_blank" href="https://colab.research.google.com/github/echosprint/TabularTransformer/blob/main/notebooks/supervised_training.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a></p>
<p>Alternatively, you can check out the <a href="https://github.com/echosprint/TabularTransformer/blob/main/notebooks/supervised_training.ipynb">notebook</a> to run it locally.</p>
<p>Please note that the hyperparameters used here are not optimized and may be suboptimal.</p>
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">&para;</a></h2>
<p>First, we need to install the <code>tabular-transformer</code> package.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">tabular</span><span class="o">-</span><span class="n">transformer</span>
</span></code></pre></div>
<p>Next, we import the necessary modules.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><span class="kn">import</span> <span class="nn">tabular_transformer</span> <span class="k">as</span> <span class="nn">ttf</span>
</span><span id="__span-1-2"><span class="kn">import</span> <span class="nn">torch</span>
</span></code></pre></div>
<h2 id="data-preparation">Data Preparation<a class="headerlink" href="#data-preparation" title="Permanent link">&para;</a></h2>
<p>We will use the <a href="https://huggingface.co/datasets/scikit-learn/adult-census-income">Adult Income dataset</a> for our prediction task, which aims to determine whether a person makes over $50K a year. The dataset contains 32.6k rows and 15 columns, with the label column named <code>income</code>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><span class="n">income_dataset_path</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">prepare_income_dataset</span><span class="p">()</span>
</span></code></pre></div>
<p>TabularTransformer treats each column feature as either <code>Categorical</code> or <code>Numerical</code>. Here, we need to specify which columns fall into each category. For convenience, one of the lists can be left empty. In the snippet below, <code>numerical_cols</code> will includes all columns that are not specified as categorical.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><span class="n">categorical_cols</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-3-2">    <span class="s1">&#39;workclass&#39;</span><span class="p">,</span> <span class="s1">&#39;education&#39;</span><span class="p">,</span>
</span><span id="__span-3-3">    <span class="s1">&#39;marital.status&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span>
</span><span id="__span-3-4">    <span class="s1">&#39;relationship&#39;</span><span class="p">,</span> <span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;sex&#39;</span><span class="p">,</span>
</span><span id="__span-3-5">    <span class="s1">&#39;native.country&#39;</span><span class="p">,</span> <span class="s1">&#39;income&#39;</span><span class="p">]</span>
</span><span id="__span-3-6">
</span><span id="__span-3-7"><span class="c1"># all remaining columns are numerical</span>
</span><span id="__span-3-8"><span class="n">numerical_cols</span> <span class="o">=</span> <span class="p">[]</span>
</span></code></pre></div>
<p>To properly instruct <code>tabular-transformer</code> on how to handle the data, we define an instance of the <code>DataReader</code>. This instance specifies which columns are categorical, which are numerical, and handles other data-related settings such as file paths, label column, header presence, ID column, etc. </p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><span class="n">income_reader</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">DataReader</span><span class="p">(</span>
</span><span id="__span-4-2">    <span class="n">file_path</span><span class="o">=</span><span class="n">income_dataset_path</span><span class="p">,</span>
</span><span id="__span-4-3">    <span class="n">ensure_categorical_cols</span><span class="o">=</span><span class="n">categorical_cols</span><span class="p">,</span>
</span><span id="__span-4-4">    <span class="n">ensure_numerical_cols</span><span class="o">=</span><span class="n">numerical_cols</span><span class="p">,</span>
</span><span id="__span-4-5">    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;income&#39;</span><span class="p">,</span>
</span><span id="__span-4-6">    <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-4-7">    <span class="nb">id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-4-8"><span class="p">)</span>
</span></code></pre></div>
<p>Optionally, we can split the data into training and testing sets if a testing set is not already available. This dataset contains a mix of numerical, categorical, and missing features. <code>tabular-transformer</code> processes the data as is, so no preprocessing is required. Here, we split 20% of the data as the testing set and use the remaining 80% for training.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><span class="n">split</span> <span class="o">=</span> <span class="n">income_reader</span><span class="o">.</span><span class="n">split_data</span><span class="p">(</span>
</span><span id="__span-5-2">    <span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">},</span>
</span><span id="__span-5-3">    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
</span><span id="__span-5-4">    <span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;data/income/&#39;</span><span class="p">,</span>
</span><span id="__span-5-5">    <span class="n">save_as</span><span class="o">=</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span>
</span><span id="__span-5-6"><span class="p">)</span>
</span><span id="__span-5-7"><span class="n">split</span>
</span></code></pre></div>
<p>we create data readers for both the training and testing datasets using the <code>income_reader</code> instance.</p>
<p>The <code>ttf.DataReader</code> instance is callable object, can be called to update specific attributes and return the updated instance. </p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><span class="n">train_data_reader</span> <span class="o">=</span> <span class="n">income_reader</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="n">split</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span>
</span><span id="__span-6-2"><span class="n">test_data_reader</span> <span class="o">=</span> <span class="n">income_reader</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="n">split</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>
</span></code></pre></div>
<h2 id="model-training">Model Training<a class="headerlink" href="#model-training" title="Permanent link">&para;</a></h2>
<p>Next, we specify the device for computation (CPU or GPU) and the data type to be used for training. We detect whether CUDA is available for acceleration; if not, we default to CPU.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
</span><span id="__span-7-2"><span class="n">dtype</span> <span class="o">=</span> <span class="s1">&#39;bfloat16&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> \
</span><span id="__span-7-3">    <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;float16&#39;</span>
</span></code></pre></div>
<p>We set up the training settings using <code>ttf.TrainSettings</code>. These settings define various configurations that guide the model's training behavior:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><span class="n">ts</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">TrainSettings</span><span class="p">(</span>
</span><span id="__span-8-2">    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-8-3">    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-8-4">    <span class="n">apply_power_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-8-5">    <span class="n">min_cat_count</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="__span-8-6"><span class="p">)</span>
</span></code></pre></div>
<p>Explanation of Parameters:</p>
<ul>
<li>
<p>device: Specifies the device (CPU or GPU) on which the training will be executed. Using a GPU (if available) can significantly speed up the training process.</p>
</li>
<li>
<p>dtype: Defines the data type (e.g., torch.float32, torch.bfloat16) used during training, which can impact memory usage and computational performance.</p>
</li>
<li>
<p>apply_power_transform: Indicates whether a power transformation should be applied to numerical features. This can help stabilize variance, making the data more suitable for training.</p>
</li>
<li>
<p>min_cat_count: Sets the minimum count (as a proportion) for categorical values. Categories occurring less frequently than this threshold will be labeled as unknown, which helps in managing rare categories effectively.</p>
</li>
</ul>
<p>Next, we define the model's hyperparameters using <code>ttf.HyperParameters</code>. These parameters determine the architecture and capacity of the TabularTransformer model:</p>
<p><div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><span class="n">hp</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">HyperParameters</span><span class="p">(</span>
</span><span id="__span-9-2">    <span class="n">dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="__span-9-3">    <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-9-4">    <span class="n">n_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span></code></pre></div>
Explanation of Hyperparameters:</p>
<ul>
<li>
<p>dim: Sets the dimensionality of the embeddings in the Transformer. A value of 64 indicates that each embedding vector will have 64 dimensions, influencing the model's capacity to capture complex patterns in the data.</p>
</li>
<li>
<p>n_heads: Specifies the number of attention heads in each multi-head attention layer. Using 8 heads allows the model to focus on different parts of the input sequence simultaneously, capturing diverse relationships within the data.</p>
</li>
<li>
<p>n_layers: Defines the number of layers (or blocks) in the Transformer. Here, 6 layers provide the depth necessary for the model to learn intricate patterns in tabular data through sequential processing.</p>
</li>
</ul>
<p>We then define the training parameters for the TabularTransformer model using <code>ttf.TrainParameters</code>. Each parameter is crucial in guiding the model's training process:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><span class="n">tp</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">TrainParameters</span><span class="p">(</span>
</span><span id="__span-10-2">    <span class="n">max_iters</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">,</span>
</span><span id="__span-10-3">    <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="s1">&#39;BINCE&#39;</span><span class="p">,</span>
</span><span id="__span-10-4">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-10-5">    <span class="n">eval_iters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">warmup_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-10-6">    <span class="n">validate_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></code></pre></div>
<p>Explanation of Parameters:</p>
<ul>
<li>
<p>max_iters: Sets the maximum number of iterations for training, determining how many times the model will go through the training data.</p>
</li>
<li>
<p>learning_rate: Controls the step size during model weight updates. A smaller value like 5e-4 ensures the model learns gradually, reducing the risk of overshooting the optimal solution.</p>
</li>
<li>
<p>output_dim: Specifies the dimension of the model's output. Here, it is set to 1, which is typical for binary classification or regression tasks.</p>
</li>
<li>
<p>loss_type: Indicates the loss function to be used during training. <code>BINCE</code> stands for Binary Cross-Entropy, commonly used for binary classification problems.</p>
</li>
<li>
<p>batch_size: The number of samples processed in each iteration. A batch size of 128 balances the need for stable gradient estimates and computational efficiency.</p>
</li>
<li>
<p>eval_interval: The model will be evaluated on the validation set every 100 iterations, allowing you to monitor its performance regularly during training.</p>
</li>
<li>
<p>eval_iters: Defines the number of iterations used during the evaluation phase. It helps average the performance over several mini-batches to get a more stable evaluation metric.</p>
</li>
<li>
<p>warmup_iters: Specifies a warm-up phase for the first 100 iterations where the learning rate gradually increases to its set value. This technique helps stabilize the initial training phase.</p>
</li>
<li>
<p>validate_split: The proportion of the dataset reserved for validation. Here, 20% of the data will be used to validate the model's performance during training, ensuring that the model is not overfitting.</p>
</li>
</ul>
<p>Finally, we create a <code>ttf.Trainer</code> instance and initiate the training process for the TabularTransformer model. We will train the model using a one-liner.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><span class="n">trainer</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">hp</span><span class="o">=</span><span class="n">hp</span><span class="p">,</span> <span class="n">ts</span><span class="o">=</span><span class="n">ts</span><span class="p">)</span>
</span><span id="__span-11-2">
</span><span id="__span-11-3"><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
</span><span id="__span-11-4">    <span class="n">data_reader</span><span class="o">=</span><span class="n">train_data_reader</span><span class="p">,</span>
</span><span id="__span-11-5">    <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
</span></code></pre></div>
<p>Explanation:</p>
<ul>
<li>
<p><code>trainer = ttf.Trainer(hp=hp, ts=ts)</code>: This line initializes the Trainer with the specified hyperparameters (<code>hp</code>) and training settings (<code>ts</code>). The Trainer is responsible for managing the training loop, optimization, and model evaluation.</p>
</li>
<li>
<p><code>trainer.train(data_reader=train_data_reader, tp=tp)</code>: This line starts the training process. It takes the <code>train_data_reader</code> to load the training data and <code>tp</code> for the training parameters (e.g., learning rate, batch size). During training, the model iteratively processes the data, adjusts its weights, and learns patterns from the input features to improve its predictive performance.</p>
</li>
</ul>
<h2 id="making-predictions">Making Predictions<a class="headerlink" href="#making-predictions" title="Permanent link">&para;</a></h2>
<p>After training the model, we use the trained model checkpoint to make predictions on the test data.</p>
<p>The code below demonstrates how to use the trained model to make predictions on the test dataset:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><span class="n">predictor</span> <span class="o">=</span> <span class="n">ttf</span><span class="o">.</span><span class="n">Predictor</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="s1">&#39;out/ckpt.pt&#39;</span><span class="p">)</span>
</span><span id="__span-12-2">
</span><span id="__span-12-3"><span class="n">prediction</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
</span><span id="__span-12-4">    <span class="n">data_reader</span><span class="o">=</span><span class="n">test_data_reader</span><span class="p">,</span>
</span><span id="__span-12-5">    <span class="n">save_as</span><span class="o">=</span><span class="s2">&quot;prediction_income.csv&quot;</span>
</span><span id="__span-12-6"><span class="p">)</span>
</span></code></pre></div>
<p>Explanation:</p>
<ul>
<li>
<p><code>predictor = ttf.Predictor(checkpoint='out/ckpt.pt')</code>: This line creates an instance of Predictor using the model checkpoint stored at 'out/ckpt.pt'. The checkpoint contains the trained model's parameters and train configurations, allowing us to make predictions on new data.</p>
</li>
<li>
<p><code>prediction = predictor.predict(data_reader=test_data_reader, save_as="prediction_income.csv")</code>: This line runs the prediction process using the <code>test_data_reader</code> to load and process the test data. The results are saved to a CSV file named <code>"prediction_income.csv"</code>. The <code>predict()</code> method generates predictions based on the patterns the model learned during training.</p>
</li>
</ul>
<p>displays the first few rows of the prediction <code>pd.DataFrame</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><span class="n">prediction</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h2>
<p>In this notebook, we demonstrated the workflow of using the TabularTransformer for handling tabular data. You can experiment with different hyperparameters and datasets to explore the model's capabilities further.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tracking", "content.code.copy", "search.highlight", "content.code.select"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.56dfad97.min.js"></script>
      
        <script src="../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>